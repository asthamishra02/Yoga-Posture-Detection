{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Processed 2139 images from C:\\Users\\debar\\Downloads\\dataset_yoga_model\\dataset_yoga_model\\train\n",
      "✅ Processed 1011 images from C:\\Users\\debar\\Downloads\\dataset_yoga_model\\dataset_yoga_model\\test\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Load MoveNet model\n",
    "movenet = hub.load(\"https://tfhub.dev/google/movenet/singlepose/lightning/4\")\n",
    "\n",
    "# Define dataset paths\n",
    "DATASET_PATH = r\"C:\\Users\\debar\\Downloads\\dataset_yoga_model\\dataset_yoga_model\"\n",
    "\n",
    "TRAIN_PATH = os.path.join(DATASET_PATH, \"train\")\n",
    "TEST_PATH = os.path.join(DATASET_PATH, \"test\")\n",
    "\n",
    "# Yoga pose classes\n",
    "POSE_CLASSES = [\"warrior\", \"tree\", \"dog\", \"no_pose\", \"shoulder_stand\", \"triangle\", \"cobra\", \"chair\"]\n",
    "\n",
    "# Function to extract keypoints using MoveNet\n",
    "def extract_keypoints(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    input_image = cv2.resize(image, (192, 192))  # Resize for MoveNet\n",
    "    input_image = np.expand_dims(input_image, axis=0)  # Add batch dimension\n",
    "    input_image = tf.convert_to_tensor(input_image, dtype=tf.int32)  # Convert to int32\n",
    "\n",
    "    # Run MoveNet model\n",
    "    outputs = movenet.signatures[\"serving_default\"](input_image)\n",
    "    keypoints = outputs[\"output_0\"].numpy().reshape(17, 3)  # 17 keypoints (x, y, confidence)\n",
    "\n",
    "    return keypoints[:, :2]  # Only return (x, y) coordinates, ignore confidence\n",
    "\n",
    "# Function to process dataset and save keypoints\n",
    "def process_dataset(data_path, save_file):\n",
    "    keypoint_data = []\n",
    "    labels = []\n",
    "\n",
    "    for pose_class in POSE_CLASSES:\n",
    "        pose_path = os.path.join(data_path, pose_class)\n",
    "        for image_name in os.listdir(pose_path):\n",
    "            image_path = os.path.join(pose_path, image_name)\n",
    "            keypoints = extract_keypoints(image_path)\n",
    "            keypoint_data.append(keypoints.flatten())  # Flatten keypoints into a single array\n",
    "            labels.append(POSE_CLASSES.index(pose_class))  # Convert class to index\n",
    "\n",
    "    # Save as NumPy arrays\n",
    "    np.save(f\"{save_file}_keypoints.npy\", np.array(keypoint_data))\n",
    "    np.save(f\"{save_file}_labels.npy\", np.array(labels))\n",
    "\n",
    "    print(f\"✅ Processed {len(labels)} images from {data_path}\")\n",
    "\n",
    "# Process train and test datasets\n",
    "process_dataset(TRAIN_PATH, \"train\")\n",
    "process_dataset(TEST_PATH, \"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\debar\\OneDrive\\Documents\\proj\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.2970 - loss: 2.0692 - val_accuracy: 0.4036 - val_loss: 1.8009\n",
      "Epoch 2/30\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6677 - loss: 1.0381 - val_accuracy: 0.4916 - val_loss: 1.4719\n",
      "Epoch 3/30\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7541 - loss: 0.7597 - val_accuracy: 0.6588 - val_loss: 1.1034\n",
      "Epoch 4/30\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7902 - loss: 0.6542 - val_accuracy: 0.7349 - val_loss: 0.8553\n",
      "Epoch 5/30\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8208 - loss: 0.5803 - val_accuracy: 0.8882 - val_loss: 0.5216\n",
      "Epoch 6/30\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8141 - loss: 0.5229 - val_accuracy: 0.9426 - val_loss: 0.3452\n",
      "Epoch 7/30\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8456 - loss: 0.4752 - val_accuracy: 0.8932 - val_loss: 0.3777\n",
      "Epoch 8/30\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8502 - loss: 0.4845 - val_accuracy: 0.9278 - val_loss: 0.2663\n",
      "Epoch 9/30\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8566 - loss: 0.4426 - val_accuracy: 0.9634 - val_loss: 0.1602\n",
      "Epoch 10/30\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8764 - loss: 0.3964 - val_accuracy: 0.9555 - val_loss: 0.1778\n",
      "Epoch 11/30\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8611 - loss: 0.3948 - val_accuracy: 0.9189 - val_loss: 0.2259\n",
      "Epoch 12/30\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8657 - loss: 0.3772 - val_accuracy: 0.9436 - val_loss: 0.2477\n",
      "Epoch 13/30\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8679 - loss: 0.4018 - val_accuracy: 0.9367 - val_loss: 0.2204\n",
      "Epoch 14/30\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8674 - loss: 0.4006 - val_accuracy: 0.9436 - val_loss: 0.1893\n",
      "Epoch 15/30\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8745 - loss: 0.3538 - val_accuracy: 0.9476 - val_loss: 0.1910\n",
      "Epoch 16/30\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8690 - loss: 0.3782 - val_accuracy: 0.9476 - val_loss: 0.1544\n",
      "Epoch 17/30\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8800 - loss: 0.3461 - val_accuracy: 0.9634 - val_loss: 0.1458\n",
      "Epoch 18/30\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8862 - loss: 0.3468 - val_accuracy: 0.9565 - val_loss: 0.1588\n",
      "Epoch 19/30\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8978 - loss: 0.3117 - val_accuracy: 0.9021 - val_loss: 0.2650\n",
      "Epoch 20/30\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8856 - loss: 0.3577 - val_accuracy: 0.9624 - val_loss: 0.1450\n",
      "Epoch 21/30\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8918 - loss: 0.3045 - val_accuracy: 0.9397 - val_loss: 0.1822\n",
      "Epoch 22/30\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9032 - loss: 0.3006 - val_accuracy: 0.9070 - val_loss: 0.2264\n",
      "Epoch 23/30\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9061 - loss: 0.2993 - val_accuracy: 0.9377 - val_loss: 0.1567\n",
      "Epoch 24/30\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9002 - loss: 0.3003 - val_accuracy: 0.9565 - val_loss: 0.1753\n",
      "Epoch 25/30\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9027 - loss: 0.2936 - val_accuracy: 0.9110 - val_loss: 0.2269\n",
      "Epoch 26/30\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9070 - loss: 0.2884 - val_accuracy: 0.9624 - val_loss: 0.1575\n",
      "Epoch 27/30\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9112 - loss: 0.2775 - val_accuracy: 0.9644 - val_loss: 0.1152\n",
      "Epoch 28/30\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9045 - loss: 0.2794 - val_accuracy: 0.9179 - val_loss: 0.2523\n",
      "Epoch 29/30\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9200 - loss: 0.2679 - val_accuracy: 0.9604 - val_loss: 0.1528\n",
      "Epoch 30/30\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9046 - loss: 0.2737 - val_accuracy: 0.8971 - val_loss: 0.2587\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9512 - loss: 0.1445\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9395 - loss: 0.1768 \n",
      "✅ Training Accuracy: 0.93\n",
      "✅ Validation Accuracy: 0.90\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "✅ IoU Score: 0.73\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "# Load extracted keypoints and labels\n",
    "X_train = np.load(\"train_keypoints.npy\")\n",
    "y_train = np.load(\"train_labels.npy\")\n",
    "X_test = np.load(\"test_keypoints.npy\")\n",
    "y_test = np.load(\"test_labels.npy\")\n",
    "\n",
    "# Normalize keypoints (scale between 0 and 1)\n",
    "X_train = X_train / np.max(X_train)\n",
    "X_test = X_test / np.max(X_test)\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "num_classes = len(np.unique(y_train))\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# Build the CNN Model\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(34,)),  # 17 keypoints * 2 (x, y)\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Dense(64, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Dense(32, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Dense(num_classes, activation='softmax')  # Output layer\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=30, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "train_loss, train_acc = model.evaluate(X_train, y_train)\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"✅ Training Accuracy: {train_acc:.2f}\")\n",
    "print(f\"✅ Validation Accuracy: {test_acc:.2f}\")\n",
    "\n",
    "# Compute IoU Score\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "iou_score = jaccard_score(y_test_classes, y_pred_classes, average='macro')\n",
    "print(f\"✅ IoU Score: {iou_score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy version: 1.26.4\n",
      "TensorFlow version: 2.18.0\n",
      "Scikit-Learn version: 1.6.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "\n",
    "print(\"NumPy version:\", np.__version__)\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Scikit-Learn version:\", sklearn.__version__)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
